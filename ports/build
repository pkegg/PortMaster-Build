#!/bin/bash
set -e
set -o pipefail

DIR="$(realpath $( dirname "${BASH_SOURCE[0]}" ))"
source ${DIR}/clone-source
source "${DIR}/ports.info"
BRANCH="${GITHUB_BRANCH}"

#docker requires lower case
GITHUB_REPO_LOWER=$(echo "$GITHUB_REPO" | tr '[:upper:]' '[:lower:]')

IMAGE_BASE=ghcr.io/${GITHUB_ORG}/${GITHUB_REPO_LOWER}
CACHE_FROM="$BRANCH"
# Update things for Pull requests
if [[ "${GITHUB_EVENT_NAME:-}" == "pull_request_target" && -n "$GITHUB_BASE_REF" && -n "$GITHUB_REF_NAME" ]] ; then
  PR_NUM=$(echo $GITHUB_REF_NAME | sed 's|/.*||g')
  BRANCH="pr-${PR_NUM}"
  CACHE_FROM="$GITHUB_BASE_REF"
  echo "branch: ${BRANCH}"
  echo "EVENT_NAME: ${GITHUB_EVENT_NAME} BASE_REF: $GITHUB_BASE_REF REF_NAME: $GITHUB_REF_NAME"
fi

# Any environment variables which need to be persistend into the build/test environment containers
# *must* be exporeted here and then added to ENV_OPTIONS.  Ex: ENV_OPTIONS="(CCACHE_DIR|ANOTHER|SOMETHING_ELSE)"
export CCACHE_DIR="../.ccache"
ENV_OPTIONS="(CCACHE_DIR)"

GITHUB_API_URL=https://api.github.com/repos
CACHE_DIR="/tmp/cache/github"

# returns true ('0') if only the package hashes matches (no need for deps)
function release_matches() {
  local package="$1"
  local dependencies_cache_a="$2"
  local dependencies_cache_b="$3"
  local dependencies_cache_a_only="$(echo -e "${dependencies_cache_a}" | grep "^${package}[=_].*")"
  local dependencies_cache_b_only="$(echo -e "${dependencies_cache_b}" | grep "^${package}[=_].*")"
  if [[ "${dependencies_cache_a_only}" == "${dependencies_cache_b_only}" ]]; then
     return 0
  else
     return 1
  fi
}

function release_full_matches() {
  local dependencies_cache_a="$1"
  local dependencies_cache_b="$2"
  local dependencies_cache_a_only="$(echo -e "${dependencies_cache_a}" | sort | grep -v "global=" | grep -v "package_" | grep -v -E '^$' )" #TODO: remove global
  local dependencies_cache_b_only="$(echo -e "${dependencies_cache_b}" | sort | grep -v "global=" | grep -v "package_"| grep -v -E '^$' )" #TODO: remove global

  echo_err "match a"
  echo_err "$dependencies_cache_a_only"
  echo_err "match b"
  echo_err "$dependencies_cache_b_only"
  if [[ "${dependencies_cache_a_only}" == "${dependencies_cache_b_only}" ]]; then
     return 0
  else
     return 1
  fi
}

function github_api() {
  local url="$1"
  local org="$2"
  local repo="$3"
  local accept="$4"
  local response
  if [[ -z "${org}" ]]; then
    org=$GITHUB_ORG
  fi
  if [[ -z "${repo}" ]]; then
    repo=$GITHUB_REPO
  fi

  if ! which wget &> /dev/null; then
    echo "ERROR: wget not found!  Please install wget."
    exit
  fi
  response="$(_github_call "${org}/${repo}/${url}" "$accept")"

  echo -e "${response}"
}
function _github_call() {
  local apiUrl="$1"
  local accept_header="$2"
  local response
  response="$(_github_call_raw "$apiUrl" "${accept_header}" |  tail -n +2 |grep -v "^[A-Za-z].*:" | tail -n +2)"
  echo -e "${response}"

}
function _github_call_raw() {
  local apiUrl="$1"
  echo_err "apiUrl=$1"
  if [[ "$apiUrl" != http* ]]; then
    apiUrl="$GITHUB_API_URL/$1"
  fi
  echo_err "apiUrl=$apiUrl"
  local cacheUrl="$1"
  local accept_header="$2"
  local headers=""
  local etag=""
  set +e
  if [[ -n "${accept_header}" ]]; then
     headers="--header=Accept:${accept_header}"
  fi
  
  local return_code
  local cache_file="$CACHE_DIR/${cacheUrl}"
  local cache_dir="$(dirname "$cache_file")"
  mkdir -p "${cache_dir}"

  echo_err "cache file: $cache_file"

  #github's etag caching for releases is unreliable (as etag seems to changes when users download)
  #So - don't redownload files downloaded in the last hour
  cache_warm_seconds="$((60*60))"
  cache_warm=false

  cache=""
  if [[ -f "$cache_file" ]]; then
    cache="$(cat "$cache_file" |col -b )"
    etag="$(_get_header "ETag" "$cache" | sed "s|^.*W/||g" )"
    echo_err "etag: '${etag}'"
    cache_date="$(_get_header "Date" "$cache" )"
    cache_date_seconds="$(date -d "$cache_date" +%s)"
    current_time_seconds="$(date +%s)"
    cache_age_seconds="$(($current_time_seconds - $cache_date_seconds))"
    echo_err "cache date: $cache_date cache_date_seconds: $cache_date_seconds current_time_seconds: $current_time_seconds cache_age_seconds: $cache_age_seconds"

  fi

  if [[ -n "$cache_age_seconds" && "$cache_age_seconds" -le "$cache_warm_seconds" ]]; then
    echo_err "Cache age seconds: $cache_age_seconds is less than cache time: $cache_warm_seconds.  Not querying API"
    echo_err "Cache hit (time): $apiUrl"
  else
    echo_err "wget --save-headers ${headers} --header="$GITHUB_AUTH" --header="If-None-Match: \"$etag\"" -O- "$apiUrl" -q"
    output="$(wget --save-headers ${headers} --header="$GITHUB_AUTH" --header="If-None-Match: \"$etag\"" -O- "$apiUrl" -q 2>&1)"
    return_raw=$?
    response="$(echo -e "${output}" | tail -n +2 | grep -v "^[A-Za-z]" | tail -n +2)"
    return_code="$(_get_return "$output")"
    #echo_err "output: $(echo -e "$output" | grep "^[A-Za-z]" )"
    
    echo_err "return http code: $return_code return code: $retu"
    if [[ "$return_code" == "200" ]]; then
      rate_limit="$(_get_header "X-RateLimit-Limit" "${output}")"
      rate_limit_remaining="$(_get_header "X-RateLimit-Remaining" "${output}")"
      rate_limit_used="$(_get_header "X-RateLimit-Used" "${output}")"
      echo_err "cache miss: $apiUrl"
      echo_err "rate limit: $rate_limit"
      echo_err "remaining: $rate_limit_remaining"
      echo_err "used: $rate_limit_used"
      echo_err "new etag: $(echo -e "$output" | grep 'ETag:') to file: $cache_file"
      echo -e "${output}" > "$cache_file"
    elif [[ "$return_code" == "404" ]]; then
      echo_err "404"
      set -e
      return
    elif [[ -n "$etag" && "$return_raw" == "8" ]]; then
      echo_err "cache hit (etag). Look at: $cache_file for more info"
    else
      echo_err "output: ${output}"
      echo_err "url: $apiUrl"
      echo_err "ERROR: Something went wrong with getting api response"
      echo_err "return http code: ${return_code} wget return code: $return_raw"
      set -e
      return
    fi
  fi
  if [[ -f "${cache_file}" ]]; then
    response="$(cat "$cache_file")"
  fi
  set -e
  echo -e "${response}"

}
function _get_header() {
  local header="$1"
  local output="$2"
  response="$(echo -e "$output" | grep "^${header}: " | sed "s|^${header}: ||g" | xargs)"
  echo -e "$response"

}
function _get_return() {
  local output="$1"
  local response
  response="$(echo  "$output" | grep "HTTP/" | head -1 | xargs  | awk '{print $2}')"
  echo -e "$response"

}
function github_api_asset_output()
{
  local release_tag="$1"
  local zip_name="$2"
  local org="$GITHUB_ORG"
  local repo="$GITHUB_REPO"
  local url="releases/${release_tag}/${zip_name}"
  local cache_url="${org}/${repo}/${url}"
  
  local cache_file="$CACHE_DIR/${cache_url}"
  mkdir -p "$(dirname $cache_file)"
  local response
  #echo_err "response: ${response}"
  browser_url="https://github.com/${org}/${repo}/releases/download/${release_tag}/${zip_name}"
  echo_err "browser url: $browser_url"

  cache_file="$cache_file-file"
  echo_err "cache file asset: $cache_file"
  if [[ -f "$cache_file" ]]; then
    response="$(cat "$cache_file")"
  else
    response="$(wget -O- "$browser_url")"
    echo -e "$response" > "$cache_file"
  fi
  echo_err "response: ${response}"
  echo -e "$response"
}
function github_api_asset_download()
{
  local asset_id="$1"
  local output_file="$2"
  local output_dir
  output_dir=$(dirname "$output_file")
  mkdir -p "${output_dir}"

  local org="$GITHUB_ORG"
  local repo="$GITHUB_REPO"
  local url="releases/assets/${asset_id}"
  local apiUrl="${org}/${repo}/${url}"
  
  local cache_file="$CACHE_DIR/${apiUrl}"
  local response
  response="$(_github_call "${apiUrl}")"
  #echo_err "response: ${response}"
  browser_url="$(echo -e "${response}" | jq ".browser_download_url" | xargs)"
  echo_err "browser url: $browser_url"

  response=$(wget -O "$output_file" "$browser_url")
  echo_err "response: ${response}"

  echo -e "$response"
}

function get_linux_platform() {
  local raw_linux_platform
  raw_linux_platform="$(uname -m)"
  if [[ "${raw_linux_platform}" == "x86_64" ]]; then
    echo "linux/amd64"
  elif [[ "${raw_linux_platform}" == "aarch64" ]]; then
    echo "linux/arm64/v8"
  elif  [[ "${raw_linux_platform}" == "armv7l" ]]; then
    echo "linux/arm/v7"
  elif [[ "${raw_linux_platform}" == "arm64" ]]; then  #M1 mac
    echo "linux/arm64/v8"
  else
    echo "unknown"
  fi

}
# outputs to stderr
function echo_err() {
  
  echo -e "$(date "+%F_%T"): $@" 1>&2;
}

function get_directory_git_hash() {
  local directory
  directory="$1"
  local no_dependencies="${2-:}"
  local pkg_name
  pkg_name=$(basename "${directory}")
  echo_err "pkgdeps pkg: ${pkg_name}" 

  pushd "${directory}"  &> /dev/null
  dirty="$(git ls-files --modified  --others --exclude-standard .)"
  echo "${pkg_name}=$(git log --pretty=tformat:"%h" -n1 .)"
  if [[ -n "${dirty}" ]]; then

     # This makes it easy to find files that have changed
     echo ${pkg_name}_dirty="$(echo -e "$dirty" | tr '\n' ',')"

     # Makes it so if any files are changed, we rebuild
     echo ${pkg_name}_dirty_hash="$(echo -e "$dirty" | xargs cat | git hash-object --stdin)"

  fi

  # Ignored files which we should still cause a rebuild
  if [[ -f "package.tmp" ]]; then
    echo package_tmp="$(git hash-object --stdin < ./package.tmp)"
  fi
  if [[ -f "package.legacy.info" ]]; then
    echo package_legacy_info="$(git hash-object --stdin < ./package.legacy.info)"
  fi
  if [[ "$pkg_name" == "global" ]]; then
    return
  else
    echo_err "package name is: '${pkg_name}'"
  fi
  echo_err "pkgdeps: ${PKG_DEPENDS}" 

  if [[ "$no_dependencies" == "true" ]]; then
    echo_err "not evaluating dependencies"
  else
    for dep in ${PKG_DEPENDS//,/ }
    do
      if [[ "$dep" == "$pkg_name" ]]; then
        continue
      fi
      echo_err "dep: ${dep}" 
      echo -e "$(get_directory_git_hash "../$dep" "true")"
    done
  fi

  popd &> /dev/null

}
function build_package() {
  local PACKAGE
  PACKAGE="$1"
  local PACKAGE_DIR
  PACKAGE_DIR="$2"
  local SOURCE_DIR="${PACKAGE_DIR}/source"
  local SOURCE_DOCKER_DIR="${PACKAGE}/source"
  local BUILD_DIR
  BUILD_DIR="$(realpath ${PACKAGE_DIR}/..)"

  if [[ -n "$PKG_URL" ]]; then
    clone_source ${PACKAGE} "${PACKAGE_DIR}"
  fi
  if [[ ! -d "${SOURCE_DIR}" ]]; then
    SOURCE_DIR="${PACKAGE_DIR}"
    SOURCE_DOCKER_DIR=""
    BUILD_DIR="$(realpath .)"
    mkdir -p "${SOURCE_DIR}"
  fi
  if [[ "$INSTALL_DEPS" == "true" && -f "${PACKAGE_DIR}/install-deps" ]]; then
    if [[ "${USE_DOCKER}" == "false" ]]; then
      echo "Installing dependencies for ${PACKAGE} without docker..."
      pushd "${PACKAGE_DIR}" &> /dev/null
      ESUDO="sudo"
      if ! which sudo &> /dev/null || [[ "$UID" == "0" ]]; then
        ESUDO=""
      fi
      $ESUDO bash "${PACKAGE_DIR}/install-deps"
      popd &> /dev/null
    fi
  fi
  if [[ -f "${PACKAGE_DIR}/build" ]]; then

    local build_command="bash -e ../build"

    if [[ "${USE_DOCKER}" == "false" ]]; then
      linux_platform=$(get_linux_platform)
      if [[ "${BUILD_PLATFORM}" == "any" || "${BUILD_PLATFORM}" != "${linux_platform}" ]]; then
        echo "--------------------------------------------------------------------------------------------------"
        echo "ERROR: BUILD_PLATFORM is set to ${BUILD_PLATFORM} but current platform is: ${linux_platform} ($(uname -m))"
        echo "  If you are attempting to cross-compile or this is in error, etc.  Please update BUILD_PLATFORM in package.info to: ${linux_platform}"
        exit 1
      fi
      if [[ "${BUILD_PLATFORM}" == "any" ]]; then
        BUILD_PLATFORM=${linux_platform}
      fi
      echo "building ${PACKAGE} without docker..."
      pushd "${SOURCE_DIR}" &> /dev/null
      if [[ "${BUILD_SHELL}" == "true" ]]; then
        build_command="bash"
        echo "starting build shell..."
      fi
      ${build_command}
      popd &> /dev/null
    else
      echo "building ${PACKAGE} with docker..."
      pushd "${SOURCE_DIR}" &> /dev/null

      DOCKER_ARGS="--pull=missing"
      if [[ "$DOCKER_REMOTE" == "true" ]]; then
        DOCKER_ARGS="--pull=always"
      fi
      # Get .env file ready
      env | grep -E "$ENV_OPTIONS" | grep "=" > .env
      if [[ "${BUILD_SHELL}" == "true" ]]; then
        build_command="bash"
        echo "starting build shell..."
      fi
      echo "build platform: ${BUILD_PLATFORM} image: ${DOCKER_IMAGE}"
      ${SUDO} ${DOCKER_CMD} run --pull=always --init --platform ${BUILD_PLATFORM} ${INTERACTIVE} ${DOCKER_ARGS} --env-file .env --rm --user ${UID}:"${GID}" -v "${BUILD_DIR}:${DOCKER_WORK_DIR}" -w "${DOCKER_WORK_DIR}/${SOURCE_DOCKER_DIR}" ${DOCKER_IMAGE} $build_command

      echo "err: $?"

      popd &> /dev/null
    fi
    if [[ "$BUILD_SHELL" == "true" ]]; then
      echo "Build shell done"
      exit 1
    fi
    echo "build done"
  fi

  if [[ -z "${TEST_PLATFORM}" ]]; then
    TEST_PLATFORM="$BUILD_PLATFORM"
  fi
  if [[ "${TEST_PLATFORM}" == "any" ]]; then
     TEST_PLATFORM=$(get_linux_platform)
  fi
  if [[ -f "${PACKAGE_DIR}/test" ]]; then
    if [[ -z "${DOCKER_WORK_DIR}" ]]; then
      DOCKER_WORK_DIR=/work
    fi

    if [[ "${USE_DOCKER}" == "false" ]]; then
        linux_platform=$(get_linux_platform)
        if [[ "${TEST_PLATFORM}" != "any" && "${TEST_PLATFORM}" != "${linux_platform}" ]]; then
          echo "--------------------------------------------------------------------------------------------------"
          echo "ERROR: TEST_PLATFORM is set to ${TEST_PLATFORM} but current platform is: ${linux_platform} ($(uname -m)"
          echo "  If you are attempting to cross-compile or this is in error, etc.  Please update TEST_PLATFORM in package.info to: ${linux_platform} or any"
          exit 1
        fi
        echo "testing ${PACKAGE} without docker..."
        pushd "${PACKAGE_DIR}" &> /dev/null
        bash "./test"
        popd &> /dev/null
    else
        echo "testing ${PACKAGE} with docker using ${DOCKER_IMAGE}..."
        pushd "${PACKAGE_DIR}" &> /dev/null
        # Get .env file ready
        env | grep -E "$ENV_OPTIONS" | grep "=" > .env
        ${SUDO} ${DOCKER_CMD} run --platform=${TEST_PLATFORM} ${INTERACTIVE} --env-file .env --rm --user ${UID}:"${GID}" -v "$(realpath ${PACKAGE_DIR}/..):${DOCKER_WORK_DIR}" -w "${DOCKER_WORK_DIR}/${PACKAGE}" ${DOCKER_IMAGE} bash -e ./test
        popd &> /dev/null
    fi
    echo "test done"
  fi
  
}
function build_env_docker_image() {
  local PACKAGE
  PACKAGE="$1"
  local PACKAGE_DIR
  PACKAGE_DIR="$2"
  local DOCKERFILE


  if [[ ! -f "${DOCKERFILE}" && -f "${PACKAGE_DIR}/install-deps" ]]; then
    DOCKERFILE="${PACKAGE_DIR}/Dockerfile.deps"
    cp "${PACKAGE_DIR}/../Dockerfile.deps.template" "${DOCKERFILE}"
  fi
  if [[ -f "${DOCKERFILE}" ]]; then
    echo "${DOCKERFILE} exists"

    DOCKER_IMAGE_CACHE_FROM=${IMAGE_BASE}/${PACKAGE}/cache:${CACHE_FROM}
    DOCKER_IMAGE_CACHE_TO=${IMAGE_BASE}/${PACKAGE}/cache:${BRANCH}

    if [[ "${USE_DOCKER_PUSH}" == "true" ]]; then
      IMAGE_CACHE_TO="--pull --builder=portmaster-remote-builder --cache-to=type=registry,ref=${DOCKER_IMAGE_CACHE_TO},mode=max --push"
    else
      IMAGE_CACHE_TO="--load --builder default"
    fi
    IMAGE_CACHE_FROM="--cache-from=type=registry,ref=${DOCKER_IMAGE_CACHE_FROM}"

    echo "docker image: ${DOCKER_IMAGE} cache from: ${DOCKER_IMAGE_CACHE_FROM} cache to: ${DOCKER_IMAGE_CACHE_TO}"

    if [[ "${USE_DOCKER}" != "false" ]]; then
      pushd "${PACKAGE_DIR}" &> /dev/null

      if [[ "${DOCKER_REMOTE}" == "true" ]]; then
        echo "Skipping local docker environment build as --remote is set"
      else
        echo "building for platform: ${BUILD_PLATFORM}"
        docker buildx build --platform ${BUILD_PLATFORM} \
          --tag "${DOCKER_IMAGE}" \
          --build-arg "DOCKER_IMAGE=${IMAGE_BASE}:${BRANCH}" \
          -f "${DOCKERFILE}" \
          ${IMAGE_CACHE_FROM} \
          ${IMAGE_CACHE_TO} .
        echo "tagged: ${DOCKER_IMAGE}"

      fi
      popd &> /dev/null
    fi 
  fi
}

function package_port() {

  PACKAGE="$1"
  PACKAGE_DIR="$2"

  mkdir -p "${PACKAGE_DIR}/pkg/"

  if [[ -f "${PACKAGE_DIR}/run" ]]; then
    cp "${PACKAGE_DIR}/run" "${PACKAGE_DIR}/pkg/run"
  fi

  for dep in ${PKG_DEPENDS//,/ }
  do
    echo "copying dep: $dep"
    cp -r ${PACKAGE_DIR}/../$dep/pkg/* ${PACKAGE_DIR}/pkg/
  done

  if [[ "$REPACKAGE_DEPENDENCIES" == "true" ]]; then
    echo "not re-running package script as we only need dependencies"
    return
  fi
  pushd "${PACKAGE_DIR}" &> /dev/null
  
  if [[ -d "./files" ]]; then
    echo "files directory exists.  Copying to pkg"
    cp -r ./files/. ./pkg
  fi

  PACKAGE_SCRIPT="./package"
  if [[ ! -f "$PACKAGE_SCRIPT" && -f "$PACKAGE_SCRIPT.tmp" && "$LEGACY_PORTMASTER" == "true" ]]; then
    PACKAGE_SCRIPT="$PACKAGE_SCRIPT.tmp"
  fi
  if [[ -f "${PACKAGE_SCRIPT}" ]]; then
    echo "Running custom package script: ${PACKAGE_SCRIPT}"

    if [[ -z "${PACKAGE_PLATFORM}" ]]; then
      PACKAGE_PLATFORM="$BUILD_PLATFORM"
    fi
    linux_platform=$(get_linux_platform)

    if [[ "${PACKAGE_PLATFORM}" == "any" ]]; then
      PACKAGE_PLATFORM=${linux_platform}
    fi
    if [[ "${USE_DOCKER}" == "false" ]]; then
        if [[ "${PACKAGE_PLATFORM}" != "any" && "${PACKAGE_PLATFORM}" != "${linux_platform}" ]]; then
          echo "--------------------------------------------------------------------------------------------------"
          echo "ERROR: PACKAGE_PLATFORM is set to ${PACKAGE_PLATFORM} but current platform is: ${linux_platform} ($(uname -m)"
          echo "  If you are attempting to cross-compile or this is in error, etc.  Please update PACKAGE_PLATFORM in package.info to: ${linux_platform} or any"
          exit 1
        fi
        echo "packaging ${PACKAGE} without docker..."
        bash -e ${PACKAGE_SCRIPT}
    else
        echo "packaging ${PACKAGE} with docker using ${DOCKER_IMAGE}..."
        # Get .env file ready
        env | grep -E "$ENV_OPTIONS" | grep "=" > .env
        ${SUDO} ${DOCKER_CMD} run --platform ${PACKAGE_PLATFORM} ${INTERACTIVE} --env-file .env --rm --user ${UID}:"${GID}" -v "$(realpath ${PACKAGE_DIR}/../..):${DOCKER_WORK_DIR}" -w "${DOCKER_WORK_DIR}/ports/${PACKAGE}" ${DOCKER_IMAGE} bash -e ${PACKAGE_SCRIPT}
    fi
  fi
  popd &> /dev/null

  if [[ -f "${PACKAGE_DIR}/pkg/run" ]] && grep -q IS_TEST_MODE "${PACKAGE_DIR}/pkg/run"; then
    echo "Running ${PACKAGE} run using IS_TEST_MODE=true"
    PORTS_DIR=/opt/roms/ports

    TEST_IMAGE=ghcr.io/${GITHUB_ORG}/${GITHUB_REPO_LOWER}:${BRANCH}
    echo "Test Image: ${TEST_IMAGE}"
    DOCKER_ARGS=""
    if [[ "${DOCKER_REMOTE}" == "true" ]]; then
      DOCKER_ARGS="--pull=always"
    fi
    if [[ "${USE_DOCKER}" == "false" ]]; then
      pushd "$PACKAGE_DIR/pkg" &> /dev/null
      IS_TEST_MODE=true bash ./run
      popd &> /dev/null
    else
      docker run ${INTERACTIVE} ${DOCKER_ARGS} --rm --platform ${TEST_PLATFORM} \
        -v "$(realpath ${PACKAGE_DIR}/pkg/):${PORTS_DIR}/${PACKAGE}" \
        -w "${PORTS_DIR}/${PACKAGE}" ${TEST_IMAGE} \
        bash -c "IS_TEST_MODE=true bash \"./run\""
      echo "run test passed"
    fi
    
  fi
  
}
function remote_cache_matches() {
  local directory="$1"

  local pkg_zip_name="$PKG_ZIP_NAME_OVERRIDE"
  if [[ -z "${pkg_zip_name}" ]]; then
    pkg_zip_name="${PKG_NAME}"
  fi

  local release_match=false
  if [[ -n "${GITHUB_TOKEN}" ]]; then
    GITHUB_AUTH="Authorization: token ${GITHUB_TOKEN}"
  fi
  if [[ -z "${GITHUB_TOKEN}" ]]; then
    echo "--remote requires setting a GITHUB_TOKEN variable to authenticate with github.  Otherwise you *will* get throttled."
    exit 1
  fi
  if ! which jq &>/dev/null ; then
    echo "jq is required.  Attempting install..."
    if [[ ${OSTYPE:-} == 'darwin'* ]]; then
      if ! brew install jq; then
        echo "Could not install jq.  Please install it!"
        exit 1
      fi
    else
      sudo apt update
      sudo apt install -y jq
    fi
  fi

  local local_dependencies_cache_calculated="$(get_directory_git_hash ${directory})"
  echo_err "local dependencies calc: ${local_dependencies_cache_calculated}"
  local releases_url="releases?per_page=3&page=1"
  echo_err "getting: ${releases_url}"
  pkg_zip_name="$(echo ${pkg_zip_name} |sed 's/%20/./g'| sed 's/ /./g' | sed 's/\.\././')" #github releases turn ' ' and '%20' into '.'.  '..' is turned into '.' (Mr. Boom -> Mr.Boom)
  echo_err "looking for asset: $pkg_zip_name"

  local attempts=3
  local attempt=-1
  local releases_raw="$(github_api "${releases_url}")"
  while [ "$attempt" -lt "$attempts" ]; do
    attempt=$((attempt+1))
    local release_id_dependencies_cache=$(echo -e "${releases_raw}" | jq ".[] | {release:.id, asset_id: .assets[] | select(.name==\"${pkg_zip_name}.zip\") | .id }"| jq -s ".[$attempt] | .release")
    
    local asset_id_zip=$(echo -e "${releases_raw}"  | jq ".[]| select(.id == ${release_id_dependencies_cache}) | .assets[] | select(.name==\"${pkg_zip_name}.zip\") | .id" | xargs )
    if [[ -z "${asset_id_zip}" ]]; then
      continue
    fi
    #local asset_id_dependencies_cache=$(echo -e "${releases_raw}" | jq ".[]| select(.id == ${release_id_dependencies_cache}) | .assets[] | select(.name==\"${pkg_zip_name}.dependencies.cache\") | .id" | xargs )
    asset_id_dependencies_cache=$(echo -e "${releases_raw}" | jq ".[]| select(.id == ${release_id_dependencies_cache}) | .assets[] | select(.name==\"${pkg_zip_name}.git.info\") | .id" | xargs )
    
    #This is for backwards compatibility with .git.info and can be removed soon
    if [[ -z "$asset_id_dependencies_cache" ]]; then
      asset_id_dependencies_cache=$(echo -e "${releases_raw}" | jq ".[]| select(.id == ${release_id_dependencies_cache}) | .assets[] | select(.name==\"${pkg_zip_name}.git.info\") | .id" | xargs )
    fi
    if [[ -z "${asset_id_dependencies_cache}" ]]; then
      continue
    fi

    echo_err "release: $release_id_dependencies_cache asset_id_zip: $asset_id_zip asset_id_dependencies_cache: $asset_id_dependencies_cache"
    #echo_err "git info: $(echo -e "$asset_id_dependencies_cache")"
    if [[ -n "$asset_id_zip" && -n "$asset_id_dependencies_cache" ]]; then
      set +e
      local release_name="$(echo -e "${releases_raw}" | jq ".[${attempt}] | .tag_name" | xargs)"
      
      local release_dependencies_cache_remote="$(github_api_asset_output "${release_name}" "${pkg_zip_name}.git.info")"
      set -e
     
      echo_err "release ${pkg_zip_name}.dependencies.cache (remote): \n${LINE}\n${release_dependencies_cache_remote}\n${LINE}"
      echo_err "local_dependencies_cache_calculated: $local_dependencies_cache_calculated"
      if release_full_matches "${local_dependencies_cache_calculated}" "${release_dependencies_cache_remote}"; then
        return 0
      fi
    fi

  done
  return 1
}
function parse_args() {
  USE_DOCKER=true
  USE_DOCKER_PUSH=false
  INSTALL_DEPS=false
  NO_RELEASE_ZIP=false
  NO_BUILD_DEPENDS=false
  DOCKER_REMOTE=false
  REMOTE_BUILD_CACHE=false
  REMOTE_BUILD_CACHE_CHECK=false
  NO_BUILD_CACHE=false
  PACKAGE=""
  PACKAGE_DIR=""
  BUILD_SHELL=""
  CLEAN=""
  FORCE_PLATFORM=""
  # Parse args
  ARGS=()
  while [[ $# -gt 0 ]]; do
    key="$1"
  
    case $key in
      --clean)
        CLEAN=true
        shift # past argument
        ;;
      --force-platform)
        FORCE_PLATFORM="$2"
        shift # past argument
        shift # past value
        ;;
      --shell)
        BUILD_SHELL=true
        NO_BUILD_CACHE=true
        NO_BUILD_DEPENDS=true
        shift # past argument
        ;;
      --no-build-deps)
        NO_BUILD_DEPENDS=true
        shift #past argument
        ;;
      -n|--no-docker)
        USE_DOCKER="false"
        shift # past argument
        ;;
      --no-release-zip)
        NO_RELEASE_ZIP="true"
        shift # past argument
        ;;
      --no-build-cache)
        NO_BUILD_CACHE="true"
        shift # past argument
        ;;
      --remote-build-cache)
        REMOTE_BUILD_CACHE="true"
        shift # past argument
        ;;
      --remote-build-cache-check)
        REMOTE_BUILD_CACHE="true"
        REMOTE_BUILD_CACHE_CHECK="true"
        shift # past argument
        ;;
      -d|--install-deps)
        INSTALL_DEPS="true"
        shift # past argument
        ;;
      --docker-remote)
        DOCKER_REMOTE="true"
        shift # past argument
        ;;
      -p|--push)
        USE_DOCKER_PUSH="true"
        shift # past argument
        ;;
      -h|--help)
        echo "$0 <package> [arguments]"
        echo "  --clean - Run ./clean before building"
        echo "  --force-platform - Builds a package on a different platform than specified in ports.info.  This typically is only for testing can can break builds.  Options: linux/amd64, linux/arm/v7, linux/arm64/v8"
        echo "  --shell - Instead of running the packages 'build' script, launch a shell for debugging.  Implies '--no-build-deps and --no-build-cache'"
        echo "  --no-docker (-n) - Runs ./build script directly without docker overhead.  For troubleshooting and internal use as part of --docker-image"
        echo "  --no-build-cache - Always rebuilds packages and does not check for a pre-build zip.  Disables --remote-build-cache if both are passed"
        echo "  --no-build-deps - Don't attempt to build dependencies"
        echo "  --no-release-zip - Won't create the zip file under release.  Primarily used internally for building libraries"    
        echo "  --install-deps (-d) - Runs the ./install-deps script automatically using 'sudo' if 'sudo' binary exists and the user is not root.  Only needed with --no-docker"
        echo "  --push (-p) - pushes docker images.  Meant for build server"
        echo "  --remote-build-cache - indicates to look for pre-built images in GitHub releases.  Requires setting GITHUB_TOKEN due to high github API usage."
        echo "  --remote-build-cache-check - implies --remote-build-cache - does not download or build, just stops when there is a cache hit (0) or miss (1)"
        echo "  --docker-remote - do not use local docker images and always pull images.  Meant to help simulate build server locally. Will not build changes to install-deps for ports"
        exit 1
        ;;
      -*)
        echo "Unknown option: $1"
        shift #past argument
        ;;
      *)    # unknown option
        if [[ -z "${PACKAGE}" ]]; then
          PACKAGE="${1%/}"
          if [[ -d "${PACKAGE}" ]]; then
            PACKAGE="$(basename ${PACKAGE})"
          fi
        else
          echo "Unknown argument: $1"
          ARGS+=("$1") # save it in an array for later
        fi
        shift
        ;;
    esac
  done
  if [[ -z "${PACKAGE}" ]]; then
    echo "Please provide port to build. Ex: $0 smw"
    exit 1
  fi
  if [[ ! -d "${DIR}/${PACKAGE}" ]]; then
    echo "Please provide a port which exists in the ports directory. ${DIR}/${PACKAGE} does not exist."
    exit 1
  fi
  PACKAGE_DIR="$(realpath "$DIR/${PACKAGE}")"

  if [[ ! -f "${PACKAGE_DIR}/package.info" ]]; then
    echo "The port '$PACKAGE' does not have a package.info file. Please create: ${PACKAGE_DIR}/package.info with appropriate values."
    exit 1
  fi
  if [[ "$USE_DOCKER" == "true" ]] && ! which docker &> /dev/null; then
    echo "WARNING: docker not found.  Assuming: --no-docker which means you must manually run in a chroot or only run cross-compile builds"
    sleep 1
    USE_DOCKER=false
  fi
}

# only run code if we are not being sourced.  This allows other scripts to source this script for function reuse
if [[ "${BASH_SOURCE[0]}" == "${0}" ]]; then
  ARGS_COPY=("$@")
  
  #Shift
  ARGS_COPY=("${ARGS_COPY[@]:1}")

  parse_args "$@"
  source "${PACKAGE_DIR}/package.info"
  echo "Building: ${PACKAGE}"
  echo "================================="
  echo "pkg depends: ${PKG_DEPENDS}"

  for dep in ${PKG_DEPENDS//,/ }
  do

    if [[ "$NO_BUILD_DEPENDS" == "true" ]]; then
      echo "skipping build of: ${dep}"
    else

      echo "building dependent package: $0 $dep"
      echo $0 "$dep" "${ARGS_COPY[@]}" --no-release-zip
  
      # shellcheck disable=2068 # code is irrelevant because we want to pass args separately
      $0 "$dep" ${ARGS_COPY[@]} --no-release-zip
    fi
  done

  if [[ -n "${FORCE_PLATFORM}" ]]; then
    BUILD_PLATFORM="${FORCE_PLATFORM}"
  fi
  if [[ "$CLEAN" == "true" ]]; then
    echo "cleaning..."
    $DIR/clean ${PACKAGE}
  fi
  if ! which zip &>/dev/null ; then
    echo "zip is required.  Attempting install..."
    sudo apt update
    sudo apt install -y zip
  fi
  if ! which unzip &>/dev/null ; then
    echo "unzip is required.  Attempting install..."
    sudo apt update
    sudo apt install -y unzip
  fi
  GITHUB_AUTH=""
  if [[ -n "${GITHUB_TOKEN}" ]]; then
    GITHUB_AUTH="Authorization: token ${GITHUB_TOKEN}"
  fi

  if [[ -z "${PKG_ZIP_NAME_OVERRIDE}" ]]; then
    PKG_ZIP_NAME_OVERRIDE="${PKG_NAME}"
  fi
  echo "PKG_ZIP_NAME_OVERRIDE: $PKG_ZIP_NAME_OVERRIDE"

  if [[ "${LEGACY_PORTMASTER}" == "true" ]]; then
    echo "Legacy Portmaster Build (Builds zip from legacy portmaster URLs)"

    # LEGACY_PORTMASTER doesn't 'build' anything (as build files are in legacy zips), so just use the current
    # platform for max speed in packaging, etc.
    if [[ -z "${BUILD_PLATFORM}" ]]; then
      BUILD_PLATFORM="$(get_linux_platform)"
    fi

    PACKAGE_INFO_LEGACY="${PACKAGE_DIR}/package.legacy.info"


    if [[ -z "$LEGACY_URL_OVERRIDE" ]]; then

      GITHUB_SHA_URL="contents?sha=${LEGACY_PORTMASTER_BRANCH}&path=/&page=1&per_page=1"
      echo "Github SHA URL: ${GITHUB_SHA_URL}"

      if ! PKG_GIT_SHA=$(github_api "$GITHUB_SHA_URL" "$LEGACY_PORTMASTER_ORG" "$LEGACY_PORTMASTER_REPO"  | grep -i "${PKG_ZIP_NAME_OVERRIDE}.zip" -A 3 | grep -i "\"sha\"" | head -1 | sed -E 's|.*: "(.*)",|\1|g'); then
         PKG_GIT_SHA=""
      fi
      if [[ -z "${PKG_GIT_SHA}" ]]; then
        echo "Could not find ${PKG_NAME}.zip in ${GITHUB_SHA_URL}"
        exit 1
      fi
      echo "PKG_GIT_SHA: $PKG_GIT_SHA"

      PKG_VERSION_URL="commits?sha=${LEGACY_PORTMASTER_BRANCH}&path=${PKG_ZIP_NAME_OVERRIDE}.zip&page=1&per_page=1"
      echo "Package Version URL: ${PKG_VERSION_URL}"

      PKG_VERSION=$(github_api "$PKG_VERSION_URL" "$LEGACY_PORTMASTER_ORG" "$LEGACY_PORTMASTER_REPO" | grep -i sha | head -1 | sed -E 's|.*: "(.*)",|\1|g')
      if [[ -z "${PKG_VERSION}" ]]; then
        debug_github "${PKG_VERSION_URL}" "${LEGACY_PORTMASTER_ORG}" "${LEGACY_PORTMASTER_REPO}"
        echo "Could not find a sha in: ${GITHUB_SHA_URL}"
        exit 1
      fi
      PKG_URL="https://github.com/${LEGACY_PORTMASTER_ORG}/${LEGACY_PORTMASTER_REPO}/raw/${PKG_VERSION}/${PKG_ZIP_NAME_OVERRIDE}.zip"
  
    else
      PKG_URL="${LEGACY_URL_OVERRIDE}"
    fi
    GET_HANDLER_SUPPORT="archive"
    echo "PKG_GIT_SHA: ${PKG_GIT_SHA} PKG_VERSION: ${PKG_VERSION} PKG_URL: ${PKG_URL}"

    rm -rf "${PACKAGE_INFO_LEGACY}"
    echo "PKG_GIT_SHA=\"${PKG_GIT_SHA}\"" >> "${PACKAGE_INFO_LEGACY}"
    echo "PKG_VERSION=\"${PKG_VERSION}\"" >> "${PACKAGE_INFO_LEGACY}"
    echo "PKG_URL=\"${PKG_URL}\"" >> "${PACKAGE_INFO_LEGACY}"
    echo "PKG_GLOBAL=\"false\"" >> "${PACKAGE_INFO_LEGACY}"
    echo "GET_HANDLER_SUPPORT=\"${GET_HANDLER_SUPPORT}\"" >> "${PACKAGE_INFO_LEGACY}"

    cp "${PACKAGE_DIR}/../package.legacy.template" "${PACKAGE_DIR}/package.tmp"
  fi
  echo "package dir: ${PACKAGE_DIR}"

  NEW_DEPENDENCIES_CACHE="$(get_directory_git_hash ${PACKAGE_DIR})"
  RELEASE_DIR="$(realpath ${PACKAGE_DIR}/../../release)"
  mkdir -p "${RELEASE_DIR}"
  RELEASE_DEPENDENCIES_CACHE_FILE="${RELEASE_DIR:?}/${PKG_ZIP_NAME_OVERRIDE}.dependencies.cache"
  RELEASE_DEPENDENCIES_CACHE_ZIP="${RELEASE_DIR:?}/${PKG_ZIP_NAME_OVERRIDE}.zip"
  
  PKG_DIRECTORY="${PACKAGE}"
  if [[ -n "${PKG_DIRECTORY_OVERRIDE}" ]]; then
    PKG_DIRECTORY="$PKG_DIRECTORY_OVERRIDE"
  fi

  if [[ -f "$RELEASE_DEPENDENCIES_CACHE_FILE" ]]; then
    RELEASE_DEPENDENCIES_CACHE_LOCAL="$(cat "${RELEASE_DEPENDENCIES_CACHE_FILE}")"
  fi
  LINE="------------------------"
  echo "$LINE"

  echo -e "release ${PKG_ZIP_NAME_OVERRIDE}.dependencies.cache (local): \n${LINE}\n${RELEASE_DEPENDENCIES_CACHE_LOCAL}\n${LINE}"

  echo -e "calculated ${PKG_ZIP_NAME_OVERRIDE}.dependencies.cache (local): \n${LINE}\n${NEW_DEPENDENCIES_CACHE}\n${LINE}"

  if [[ "$NO_BUILD_CACHE" == "true" ]]; then
    echo "Not using build cache..."
  elif [[ ! -d "${PACKAGE_DIR}/pkg" ]] || [[ -z $(ls -A "${PACKAGE_DIR}/pkg") ]]; then
    echo "pkg directory seems to have been removed - rebuilding"
  elif [[ "${NEW_DEPENDENCIES_CACHE}" == "${RELEASE_DEPENDENCIES_CACHE_LOCAL}" ]]; then
    echo "Build already exists - local"
    exit 0
  fi
  echo "use remote build cache: ${REMOTE_BUILD_CACHE}"
  if [[ "${REMOTE_BUILD_CACHE}" == "true" && "$NO_BUILD_CACHE" == "false" ]]; then
    
    if remote_cache_matches "$DIR/$PACKAGE"; then
      if [[ "${REMOTE_BUILD_CACHE_CHECK}" == "true" ]]; then
        echo "Remote build already exists - check only so no download"
        exit 0
      fi
      echo "Build already exists - remote - downloading..."
      echo "Finding: ${PKG_ZIP_NAME_OVERRIDE_GITHUB}.zip"
      echo "PKG_LIBRARY: ${PKG_LIBRARY}"
      echo "asset id zip: ${asset_id_zip}"
      github_api_asset_download "${asset_id_zip}" "${RELEASE_DEPENDENCIES_CACHE_ZIP}"

      pushd "$RELEASE_DIR" &> /dev/null

      if [[ -f "$RELEASE_DEPENDENCIES_CACHE_ZIP" ]]; then
        rm -rf "./${PKG_NAME}"
        if unzip -o "${RELEASE_DEPENDENCIES_CACHE_ZIP}"; then
          echo "download: ${PKG_ZIP_NAME_OVERRIDE} directory: ${PKG_DIRECTORY_OVERRIDE}"
          
          if [[ -d "${PACKAGE_DIR}/pkg" ]]; then
            chmod +w -R "${PACKAGE_DIR}/pkg" #srb2kart has non-writable permissions to owner -this works around permission probems in remove
            rm -rf "${PACKAGE_DIR}/pkg"
          fi
          cp -r "${PKG_DIRECTORY}" "${PACKAGE_DIR}/pkg"
  
          echo "Updating git info: $RELEASE_DEPENDENCIES_CACHE_FILE"
          echo -e "${release_dependencies_cache_remote}" > "$RELEASE_DEPENDENCIES_CACHE_FILE"
          echo "Remote download success"
          
          # only exit if it was an exact match, a partial match we need to repackage
          if [[ "${NEW_DEPENDENCIES_CACHE}" == "${release_dependencies_cache_remote}" ]]; then
            exit 0
          fi
        else
          echo "downloaded zip seems corrupted"
        fi
      else
        echo "zip not found.  Something went wrong downloading.."
      fi 
    fi
    if [[ "${REMOTE_BUILD_CACHE_CHECK}" == "true" ]]; then
      echo "No remote build found that matches"
      exit 1
    fi
    echo 'remote checking done'
  fi

  if [[ -f "$RELEASE_DEPENDENCIES_CACHE_FILE" ]]; then
    RELEASE_DEPENDENCIES_CACHE_LOCAL="$(cat "${RELEASE_DEPENDENCIES_CACHE_FILE}")"
  fi
  # Default BUILD_PLATFORM to arm64 unless set in package.info or by LEGACY_PORTMASTER
  if [[ -z "$BUILD_PLATFORM" ]]; then
    BUILD_PLATFORM="linux/arm64/v8"
  fi

  echo "USE_DOCKER: ${USE_DOCKER} USE_DOCKER_PUSH: ${USE_DOCKER_PUSH} BUILD_PLATFORM: ${BUILD_PLATFORM}"

  # Set global docker variables
  if [[ -z "${DOCKER_WORK_DIR}" ]]; then
    DOCKER_WORK_DIR=/work
  fi

  GID=$(id -g)
  DOCKER_CMD=docker

  # Use 'sudo' if docker ps doesn't work.  In theory, other things than missing sudo could cause this.  But sudo needed is a common issue and easy to fix.
  SUDO=""
  if ! docker ps -q &> /dev/null && sudo docker ps -q &> /dev/null; then
   SUDO="sudo"
  fi

  # Launch docker as interactive if this is an interactive shell (allows ctrl-c for manual and running non-interactive - aka: build server)
  INTERACTIVE=""
  if [ -t 0 ]; then
    INTERACTIVE="-it"
  fi
  DOCKERFILE="${PACKAGE_DIR}/Dockerfile"
  if [[ -f "${DOCKERFILE}" || -f "${PACKAGE_DIR}/install-deps" ]]; then
    DOCKER_IMAGE=${IMAGE_BASE}/${PACKAGE}:${BRANCH}
  else
    echo "${PACKAGE_DIR}/Dockerfile does not exist"
    DOCKER_IMAGE=${IMAGE_BASE}:${BRANCH}
  fi
  #if the release git info matches (but not dependencies, or it would have been an exact match), we don't need to rebuild, just repackage
  # - Still rebuild on NO_BUILD_CACHE (--no-build-cache)
  # - Still rebuild if the /pkg directory is empty for some reason
  if ! release_matches "${PACKAGE}" "${NEW_DEPENDENCIES_CACHE}" "${RELEASE_DEPENDENCIES_CACHE_LOCAL}" || [[ "${NO_BUILD_CACHE}" == "true" ]] || [[ ! -d "${PACKAGE_DIR}/pkg" ]] || [[ -z $(ls -A "${PACKAGE_DIR}/pkg") ]]; then
    rm -rf "${PACKAGE_DIR}/pkg"
    mkdir -p "${PACKAGE_DIR}/pkg/"
    build_env_docker_image "$PACKAGE" "$PACKAGE_DIR"
    build_package "$PACKAGE" "$PACKAGE_DIR"
  else
    REPACKAGE_DEPENDENCIES=true
    echo "Dependencies changed - need to repackage"
  fi

  package_port "$PACKAGE" "$PACKAGE_DIR"

  mkdir -p "${RELEASE_DIR}"

  GLOBAL_DIR="$(realpath ${PACKAGE_DIR}/../global)"
  pushd "${PACKAGE_DIR}/pkg" &> /dev/null

  echo "Release dir: ${RELEASE_DIR}"
  ZIP_FILE="${RELEASE_DIR}/${PKG_ZIP_NAME_OVERRIDE}.zip"
  rm -rf "${RELEASE_DIR:?}/${PKG_ZIP_NAME_OVERRIDE}"
  rm -rf "${RELEASE_DIR:?}/${PKG_ZIP_NAME_OVERRIDE}.zip"

  echo -e "$NEW_DEPENDENCIES_CACHE" > "${RELEASE_DEPENDENCIES_CACHE_FILE}"

  if [[ "${NO_RELEASE_ZIP}" == "false" ]]; then
    echo "Preparing release zip..."
    mkdir -p "${RELEASE_DIR:?}/${PKG_NAME}/"

    MAIN_SCRIPT_LOCATION="${RELEASE_DIR}/${PKG_NAME}/${PKG_NAME}.sh"
    if [[ "${PKG_NO_MAIN_SCRIPT}" == "true" ]]; then
      echo "Not creating a main: ${PKG_NAME}.sh script due to PKG_NO_MAIN_SCRIPT=true"
    elif [[ "${PKG_LIBRARY}" == "true" ]]; then
      echo "Not creating a main: ${PKG_NAME}.sh script as PKG_LIBRARY=true"
    elif [[ -f "${PACKAGE_DIR}/${PKG_NAME}.sh" ]]; then
      echo "Utilizing ${PKG_NAME}.sh for main script"
      cp "${PACKAGE_DIR}/${PKG_NAME}.sh" "${MAIN_SCRIPT_LOCATION}"
    elif [[ -f "${PACKAGE_DIR}/run-legacy" ]]; then
      echo "Utilizing run-legacy for main script"
      cp "${PACKAGE_DIR}/run-legacy" "${MAIN_SCRIPT_LOCATION}"
    elif [[ "${LEGACY_PORTMASTER}"  == "true" \
           && ! -f "${PACKAGE_DIR}/run" ]]; then
      echo "Utilizing existing (legacy) .sh script"
      cp ${PACKAGE_DIR}/source/*.sh "${MAIN_SCRIPT_LOCATION}" || true #ok if no .sh files exist
    else
      echo "Utilizing standard run script"
      cp "${GLOBAL_DIR}/global-run.sh" "${MAIN_SCRIPT_LOCATION}"
      sed -i.bak "s/__PACKAGE__/${PACKAGE}/g" "${MAIN_SCRIPT_LOCATION}"
      rm -f "${MAIN_SCRIPT_LOCATION}.bak"
    fi
    echo "copying to package"
    cp -R ./ "${RELEASE_DIR}/${PKG_NAME}/${PKG_DIRECTORY}"
    popd &> /dev/null
  
    pushd "${RELEASE_DIR}/${PKG_NAME}" &> /dev/null || exit 1
    echo "Zipping..."
    zip -FSqr "${ZIP_FILE}" .
    popd &> /dev/null
  fi

  echo "========================================="
  echo "Build done: ${PACKAGE}"
  echo ""

fi
